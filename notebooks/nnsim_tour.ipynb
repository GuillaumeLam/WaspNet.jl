{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `nnsim.jl` Tour\n",
    "This notebook serves as a tutorial or tour of sorts of `nnsim`, a Julia package intended for forward simulation of neural networks (NNs). \n",
    "\n",
    "`nnsim` provides the general structure of a neural network topology from neurons to layers and full networks. The dynamics of neurons are specified by the user in the form of update mathematical update rules. Given a mathematical description of the neuron, `nnsim` then stacks these neurons into layers and networks which can be used for simulation or inference. \n",
    "\n",
    "In principle, both artificial and spiking NNs are supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Revise # Used for development\n",
    "using Parameters\n",
    "using nnsim\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons\n",
    "The fundamental building block of a NN is the neuron. `nnsim` includes an `AbstractNeuron` type to be implemented by the user for their specified type. The full implementation of an _Izhikevich_ neuron is contained in the cell below.\n",
    "\n",
    "For now, the only functions necessary for implementing a neural network are:\n",
    "1. `update!` which implements the update rule for the neuron, including a concept of time\n",
    "2. `reset!` which resets the neuron to its default state\n",
    "\n",
    "It is important that any state variables in the type be stored within an `Array` under the name `state`, or otherwise the struct must be declared mutable. Code for tracking the internal states of the neurons requires the state(s) to be tracked be stored in a parameter named `state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Izh{F}<:AbstractNeuron\n",
    "   a::F = 0.02      # a-d are model parameters\n",
    "   b::F = 0.2\n",
    "   c::F = -65.\n",
    "   d::F = 8.\n",
    "   I::F = 25.       # Background current injection (mA)\n",
    "   θ::F = 30.       # Threshold potential (mV)\n",
    "\n",
    "   v0::F = -65.     # Reset voltage (mV)\n",
    "   u0::F = 0.       # Reset state variable\n",
    "   state::Array{F,1} = [-65., 0.]      # Membrane potential (mV) and state variable\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nnsim.update!(neuron::Izh, input_update, dt, t)\n",
    "    retval = 0\n",
    "    # If an impulse came in, add it\n",
    "    neuron.state[1] += input_update\n",
    "    \n",
    "    neuron.state[1] += dt*(0.04 * neuron.state[1]^2 + 5*neuron.state[1] + 140 - neuron.state[2] + neuron.I)\n",
    "    neuron.state[2] += dt*(neuron.a)*(neuron.b*neuron.state[1]-neuron.state[2])\n",
    "    \n",
    "    # Check for thresholding\n",
    "    if neuron.state[1] >= neuron.θ\n",
    "        neuron.state[1] = neuron.v0\n",
    "        neuron.state[2] = neuron.state[2] + neuron.d\n",
    "        retval = 1\n",
    "    end\n",
    "\n",
    "    return retval\n",
    "end\n",
    "\n",
    "function nnsim.reset!(neuron::Izh)\n",
    "    neuron.state .= [neuron.v0, neuron.u0]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "We're now ready to build layers and a full network out of these neurons!\n",
    "\n",
    "A layer is a collection of neurons with input weights. For this reason, we need to specify both the input weights as well as the neurons that make up our layer. \n",
    "\n",
    "Let's construct two layers of eight homogeneous Izhikevich neurons each, all with the default parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "\n",
    "W1 = randn(N,2) # Random NxN matrix\n",
    "W1 = W1./maximum(abs.(W1)) # Normalize\n",
    "L1 = batch_layer_construction(Izh, W1, N) # Layer 1\n",
    "\n",
    "W2 = randn(N,N) \n",
    "L2 = batch_layer_construction(Izh, W2, N); # Layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks\n",
    "We can supply the list of layers to construct a network. Then we simulate the network with constant inputs of `[0., -.002]` for 240 seconds with 1 millisecond time steps.\n",
    "\n",
    "On the development machine this simulation executes in about 1.6 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([L1, L2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.001\n",
    "tf = 240.\n",
    "t0 = 0.\n",
    "\n",
    "reset!(net)\n",
    "input(t) = [0., -0.02]\n",
    "@time outputs, states = simulate!(net, input, dt, tf, track_flag = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot membrane potentials, skip the recovery variable\n",
    "plot(t0:dt:tf, transpose(states[1:2:end,2:end]))\n",
    "xlabel(\"Time (s)\")\n",
    "ylabel(\"Membrane Potential (mV)\")\n",
    "title(\"Membrane Potential of Each Neuron\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spiking event plot for network\n",
    "xs = []\n",
    "ys = []\n",
    "for pt in findall(outputs.>0)\n",
    "    push!(xs, pt[2]*dt)\n",
    "    push!(ys, pt[1])\n",
    "end\n",
    "scatter(xs, ys)\n",
    "xlabel(\"Time (s)\")\n",
    "ylabel(\"Neuron\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking and Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f()\n",
    "    update!(net.layers[1], [0., -0.02], 0.001, 99)\n",
    "    @time update!(net.layers[1], [0., -0.02], 0.001, 99)\n",
    "    update!(net.layers[1], 0, 0.001, 99)\n",
    "    @time update!(net.layers[1], 0, 0.001, 99)\n",
    "end\n",
    "f();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
